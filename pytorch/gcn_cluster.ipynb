{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GraphConvolution(Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, k_cluster, t, v, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.k_cluster = k_cluster\n",
    "        self.t = t\n",
    "        self.v = v\n",
    "        self.weight = nn.Parameter(torch.rand(k_cluster, in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj, c):\n",
    "        b = input.size()[0] \n",
    "        # c*w  , c.shape = (b,n,k)  \n",
    "        output = torch.mm(c.view(-1,self.k_cluster) , self.weight.view(self.k_cluster, -1))  # c * w  , out : (b, n,f1*f2)\n",
    "        output = output.view(-1, self.v, self.in_features, self.out_features)  #b , n, f1, f2\n",
    "\n",
    "        # xcw  , (b, n ,t , f1)  * (b,  n , f1 , f2)   , output: (b, n,t , f2)  \n",
    "        input = input.contiguous().view(-1, self.t , self.in_features)\n",
    "        output = output.contiguous().view(-1,self.in_features , self.out_features)\n",
    "        \n",
    "        output = torch.bmm(input, output).view(-1,self.v , self.t , self.out_features )\n",
    "\n",
    "        # gcn , (b,n, n) * ( b, n , t*f2)\n",
    "        graph = adj\n",
    "        graph.unsqueeze(-1)\n",
    "        graph = graph.repeat(b ,1,1)  # shape : (b , n , n) \n",
    "        output = torch.bmm(graph, output.view( b, self.v, self.t * self.out_features))\n",
    "        output = output.view(-1, self.v , self.t , self.out_features)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "\n",
    "    def compute_output_shape(self, input_shapes):\n",
    "        batch_size = input_shapes[0]\n",
    "        graph_size = input_shapes[1]\n",
    "        return (batch_size, graph_size, self.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ClusterBlock(nn.Module):\n",
    "    def __init__(self, n_input, n_output, v ,T, k_cluster):\n",
    "        super(ClusterBlock, self).__init__( )\n",
    "        self.n_input = n_input\n",
    "        self.n_output = n_output\n",
    "        self.v = v  # number of node\n",
    "        self.T = T\n",
    "        self.k_cluster = k_cluster\n",
    "        self.linear1 = nn.Linear(n_input , 1)  # Dense\n",
    "        self.linear2 = nn.Linear(T ,k_cluster ) # clustering\n",
    "        self.softmax = nn.Softmax(dim =-1)\n",
    "        self.gc1 = GraphConvolution(n_input, n_output,k_cluster,self.T , self.v)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x, graph):  # x.shape = (b,v,T,f)\n",
    "        # squeeze f\n",
    "        out = self.linear1(x)    #  out.shape = (b , v ,T,1)\n",
    "        out = out.view(-1  , self.v , self.T)  #  out.shape = (b , v ,T)\n",
    "\n",
    "        # clustering\n",
    "        out =self.linear2(out)  \n",
    "        out = self.softmax(out)   # out.shape = (b,v,k)\n",
    "        \n",
    "        #gcn  LXcw\n",
    "        c = out\n",
    "        out  = F.relu(self.gc1(x,graph,out))\n",
    "        out = self.dropout(out)\n",
    "        return out , c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    ''' Scaled Dot-Product Attention '''\n",
    "\n",
    "    def __init__(self, temperature, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "\n",
    "        attn = torch.bmm(q, k.transpose(1, 2))\n",
    "        attn = attn / self.temperature\n",
    "\n",
    "        if mask is not None:\n",
    "            attn = attn.masked_fill(mask, -np.inf)  # fill the place with -inf where mask tensor is 1.\n",
    "\n",
    "        attn = self.softmax(attn)\n",
    "        attn = self.dropout(attn)\n",
    "        output = torch.bmm(attn, v)\n",
    "\n",
    "        return output, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Define the sublayers in encoder/decoder layer '''\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    ''' Multi-Head Attention module '''\n",
    "\n",
    "    def __init__(self, n_head, d_model_in, d_model_out, d_k, d_v, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model_out == n_head * d_k\n",
    "        self.n_head = n_head\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "            \n",
    "        self.w_qs = nn.Linear(d_model_out, n_head * d_k)\n",
    "        self.w_ks = nn.Linear(d_model_in, n_head * d_k)\n",
    "        self.w_vs = nn.Linear(d_model_in, n_head * d_v)\n",
    "        nn.init.normal_(self.w_qs.weight, mean=0, std=np.sqrt(2.0 / (d_model_in + d_k)))\n",
    "        nn.init.normal_(self.w_ks.weight, mean=0, std=np.sqrt(2.0 / (d_model_in + d_k)))\n",
    "        nn.init.normal_(self.w_vs.weight, mean=0, std=np.sqrt(2.0 / (d_model_in + d_v)))\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(temperature=np.power(d_k, 0.5))\n",
    "        self.layer_norm = nn.LayerNorm(d_model_out)\n",
    "\n",
    "        self.fc = nn.Linear(n_head * d_v, d_model_out)\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "\n",
    "        d_k, d_v, n_head = self.d_k, self.d_v, self.n_head\n",
    "\n",
    "        sz_b, len_q, _ = q.size()\n",
    "        sz_b, len_k, _ = k.size()\n",
    "        sz_b, len_v, _ = v.size()\n",
    "\n",
    "        residual = q\n",
    "        q = self.w_qs(q).view(sz_b, len_q, n_head, d_k)\n",
    "        k = self.w_ks(k).view(sz_b, len_k, n_head, d_k)\n",
    "        v = self.w_vs(v).view(sz_b, len_v, n_head, d_v)\n",
    "\n",
    "        q = q.permute(2, 0, 1, 3).contiguous().view(-1, len_q, d_k) # (n*b) x lq x dk\n",
    "        k = k.permute(2, 0, 1, 3).contiguous().view(-1, len_k, d_k) # (n*b) x lk x dk\n",
    "        v = v.permute(2, 0, 1, 3).contiguous().view(-1, len_v, d_v) # (n*b) x lv x dv\n",
    "        \n",
    "        if mask is not None:\n",
    "            mask = mask.repeat(n_head, 1, 1) # (n*b) x .. x ..\n",
    "        output, attn = self.attention(q, k, v, mask=mask)\n",
    "\n",
    "        output = output.view(n_head, sz_b, len_q, d_v)\n",
    "        output = output.permute(1, 2, 0, 3).contiguous().view(sz_b, len_q, -1) # b x lq x (n*dv)\n",
    "\n",
    "        output = self.dropout(self.fc(output))\n",
    "        output = self.layer_norm(output + residual)\n",
    "\n",
    "        return output, attn\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    ''' A two-feed-forward-layer module '''\n",
    "\n",
    "    def __init__(self, d_in, d_hid, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.w_1 = nn.Conv1d(d_in, d_hid, 1) # position-wise\n",
    "        self.w_2 = nn.Conv1d(d_hid, d_in, 1) # position-wise\n",
    "        self.layer_norm = nn.LayerNorm(d_in)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        output = x.transpose(1, 2)\n",
    "        output = self.w_2(F.relu(self.w_1(output)))\n",
    "        output = output.transpose(1, 2)\n",
    "        output = self.dropout(output)\n",
    "        output = self.layer_norm(output + residual)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Define the Layers '''\n",
    "class EncoderLayer(nn.Module):\n",
    "    ''' Compose with two layers '''\n",
    "\n",
    "    def __init__(self, d_model, d_inner, n_head, d_k, d_v, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.slf_attn = MultiHeadAttention(n_head, d_model, d_model, d_k, d_v, dropout=dropout)\n",
    "        self.pos_ffn = PositionwiseFeedForward(d_model, d_inner, dropout=dropout)\n",
    "\n",
    "    def forward(self, enc_input_qk, enc_input_v, slf_attn_mask=None):\n",
    "        enc_output, enc_slf_attn = self.slf_attn(enc_input_qk, enc_input_qk, enc_input_v, mask=slf_attn_mask)\n",
    "        enc_output = self.pos_ffn(enc_output)\n",
    "        return enc_output, enc_slf_attn\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    ''' Compose with three layers '''\n",
    "\n",
    "    def __init__(self, d_model_in, d_model_out, d_inner, n_head, d_k, d_v, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.slf_attn = MultiHeadAttention(n_head, d_model_out, d_model_out, d_k, d_v, dropout=dropout)\n",
    "        self.enc_attn = MultiHeadAttention(n_head, d_model_in, d_model_out, d_k, d_v, dropout=dropout)\n",
    "        self.pos_ffn = PositionwiseFeedForward(d_model_out, d_inner, dropout=dropout)\n",
    "\n",
    "    def forward(self, dec_input_qk, dec_input_v, enc_output, slf_attn_mask=None):\n",
    "        dec_output, dec_slf_attn = self.slf_attn(dec_input_qk, dec_input_qk, dec_input_v, mask=slf_attn_mask)\n",
    "        dec_output, dec_enc_attn = self.enc_attn(dec_output, enc_output, enc_output, mask=None)\n",
    "        dec_output = self.pos_ffn(dec_output)\n",
    "        return dec_output, dec_slf_attn, dec_enc_attn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''A wrapper class for optimizer '''\n",
    "import numpy as np\n",
    "\n",
    "class ScheduledOptim():\n",
    "    '''A simple wrapper class for learning rate scheduling'''\n",
    "\n",
    "    def __init__(self, optimizer, d_model, n_warmup_steps):\n",
    "        self._optimizer = optimizer\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.n_current_steps = 0\n",
    "        self.init_lr = np.power(d_model, -0.5)\n",
    "\n",
    "    def step_and_update_lr(self):\n",
    "        \"Step with the inner optimizer\"\n",
    "        self._update_learning_rate()\n",
    "        self._optimizer.step()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"Zero out the gradients by the inner optimizer\"\n",
    "        self._optimizer.zero_grad()\n",
    "\n",
    "    def _get_lr_scale(self):\n",
    "        return np.min([\n",
    "            np.power(self.n_current_steps, -0.5),\n",
    "            np.power(self.n_warmup_steps, -1.5) * self.n_current_steps])\n",
    "\n",
    "    def _update_learning_rate(self):\n",
    "        ''' Learning rate scheduling per step '''\n",
    "\n",
    "        self.n_current_steps += 1\n",
    "        lr = self.init_lr * self._get_lr_scale()\n",
    "\n",
    "        for param_group in self._optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Define the Transformer model '''\n",
    "\n",
    "def get_subsequent_mask(seq):\n",
    "    ''' For masking out the subsequent info. '''\n",
    "\n",
    "    sz_b, len_s = seq.size()[:-1]\n",
    "    subsequent_mask = torch.triu(\n",
    "        torch.ones((len_s, len_s), device=seq.device, dtype=torch.uint8), diagonal=1)\n",
    "    subsequent_mask = subsequent_mask.unsqueeze(0).expand(sz_b, -1, -1)  # b x ls x ls\n",
    "\n",
    "    return subsequent_mask\n",
    "\n",
    "def cal_weekly(n_position):\n",
    "    return np.array([(2 * np.pi / 7) * (i / 48) for i in range(n_position)])\n",
    "\n",
    "def cal_daily(n_position):\n",
    "    return np.array([2 * np.pi * (i / 48) for i in range(n_position)])\n",
    "\n",
    "def get_qk_encoding_table(n_position, d_hid):\n",
    "\n",
    "    def cal_closeness(t, f):\n",
    "        closeness_vec = np.array([np.exp(-(i / 48) ** 2) for i in range(t)])\n",
    "        return closeness_vec.reshape(-1, 1).repeat(f, axis=-1)\n",
    "\n",
    "    def cal_compensation(t, f):\n",
    "        compensation_vec = np.array([np.exp(-((i / 48) % 7 + 3.5) ** 2) for i in range(t)])\n",
    "        return compensation_vec.reshape(-1, 1).repeat(f, axis=-1)\n",
    "\n",
    "    weekly_table = cal_weekly(n_position).reshape(-1, 1).repeat(d_hid, axis=-1)\n",
    "    daily_table = cal_daily(n_position).reshape(-1, 1).repeat(d_hid, axis=-1)\n",
    "    weekly_table[:, 0::2] = np.sin(weekly_table[:, 0::2])  # dim 2i\n",
    "    weekly_table[:, 1::2] = np.cos(weekly_table[:, 1::2])  # dim 2i+1\n",
    "    daily_table[:, 0::2] = np.sin(daily_table[:, 0::2])  # dim 2i\n",
    "    daily_table[:, 1::2] = np.cos(daily_table[:, 1::2])  # dim 2i+1\n",
    "\n",
    "    return torch.FloatTensor(np.array([weekly_table, daily_table, \n",
    "                                       cal_closeness(n_position, d_hid), \n",
    "                                       cal_compensation(n_position, d_hid)]).transpose(1,2,0).reshape(-1, 4))\n",
    "\n",
    "\n",
    "def get_v_encoding_table(n_position, d_hid):\n",
    "\n",
    "    weekly_table = cal_weekly(n_position).reshape(-1, 1).repeat(d_hid, axis=-1)\n",
    "    daily_table = cal_daily(n_position).reshape(-1, 1).repeat(d_hid, axis=-1)\n",
    "    weekly_table[:, 0::2] = np.sin(weekly_table[:, 0::2])  # dim 2i\n",
    "    weekly_table[:, 1::2] = np.cos(weekly_table[:, 1::2])  # dim 2i+1\n",
    "    daily_table[:, 0::2] = np.sin(daily_table[:, 0::2])  # dim 2i\n",
    "    daily_table[:, 1::2] = np.cos(daily_table[:, 1::2])  # dim 2i+1\n",
    "\n",
    "    closeness_vec = np.array([-2 * (i / 48) for i in range(n_position)])\n",
    "    closeness_table = closeness_vec.reshape(-1, 1).repeat(d_hid, axis=-1)\n",
    "\n",
    "    compensation_vec = np.array([-2 * ((i / 48) % 7 + 3.5) for i in range(n_position)])\n",
    "    compensation_table = compensation_vec.reshape(-1, 1).repeat(d_hid, axis=-1)\n",
    "\n",
    "    # if padding_idx is not None:\n",
    "    #     # zero vector for padding dimension\n",
    "    #     sinusoid_table[padding_idx] = 0.\n",
    "    return torch.FloatTensor(np.array([weekly_table, daily_table, \n",
    "                                       closeness_table, compensation_table]).transpose(1,2,0).reshape(-1, 4))\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    ''' A encoder model with self attention mechanism. '''\n",
    "\n",
    "    def __init__(self, n_input, n_output, v, T, k_cluster, \n",
    "                 n_layers, n_head, d_k, d_v, d_model, d_inner, dropout=0.1):\n",
    "\n",
    "        super().__init__()\n",
    "        self.cluster_block = ClusterBlock(n_input, n_output, v, T, k_cluster)\n",
    "        self.n_output = n_output\n",
    "        self.position_enc = nn.Linear(4, 1, bias=False)\n",
    "        self.d_model = d_model\n",
    "        self.layer_stack = nn.ModuleList([\n",
    "            EncoderLayer(d_model, d_inner, n_head, d_k, d_v, dropout=dropout)\n",
    "            for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, src_seq, src_pos, graph, return_attns=False):\n",
    "        sz_b, v, t, f = src_seq.size()\n",
    "        enc_slf_attn_list = []\n",
    "        cluster_mat = []\n",
    "        # -- Forward\n",
    "        src_seq, cluster = self.cluster_block(src_seq, graph)\n",
    "        cluster_mat += [cluster]\n",
    "        src_seq = src_seq.permute(0, 2, 1, 3).contiguous().view(sz_b, t, -1)  # (b, t, v*f2)\n",
    "        pe_qk = self.position_enc(get_qk_encoding_table(src_pos, self.d_model).to(src_seq.device)).view(src_pos, -1)\n",
    "        pe_v = self.position_enc(get_v_encoding_table(src_pos, self.d_model).to(src_seq.device)).view(src_pos, -1)\n",
    "        enc_output_qk = src_seq + pe_qk\n",
    "        enc_output_v = src_seq + pe_v\n",
    "        enc_output, enc_slf_attn = self.layer_stack[0](enc_output_qk, enc_output_v)\n",
    "        \n",
    "        if return_attns:\n",
    "            enc_slf_attn_list += [enc_slf_attn]\n",
    "\n",
    "        for enc_layer in self.layer_stack[1:]:\n",
    "            enc_output = enc_output.view(sz_b, t, v, self.n_output).permute(0, 2, 1, 3)  # (b, v, t, f2)\n",
    "            enc_output, cluster = self.cluster_block(enc_output, graph)\n",
    "            cluster_mat += [cluster]\n",
    "            enc_output = enc_output.permute(0, 2, 1, 3).contiguous().view(sz_b, t, -1)\n",
    "            enc_output, enc_slf_attn = enc_layer(enc_output, enc_output)\n",
    "\n",
    "            if return_attns:\n",
    "                enc_slf_attn_list += [enc_slf_attn]\n",
    "\n",
    "        if return_attns:\n",
    "            return enc_output, enc_slf_attn_list, cluser_mat\n",
    "        return enc_output, cluster_mat\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    ''' A decoder model with self attention mechanism. '''\n",
    "\n",
    "    def __init__(self, n_layers, n_head, d_k, d_v, d_model_in, d_model_out, d_inner, dropout=0.1):\n",
    "\n",
    "        super().__init__()\n",
    "        self.position_enc = nn.Linear(4, 1, bias=False)\n",
    "        self.d_model_in = d_model_in\n",
    "        self.d_model_out = d_model_out\n",
    "\n",
    "        self.layer_stack = nn.ModuleList([\n",
    "            DecoderLayer(d_model_in, d_model_out, d_inner, n_head, d_k, d_v, dropout=dropout)\n",
    "            for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, tgt_seq, tgt_pos, enc_output, return_attns=False):\n",
    "\n",
    "        dec_slf_attn_list, dec_enc_attn_list = [], []\n",
    "        slf_attn_mask_subseq = get_subsequent_mask(tgt_seq)\n",
    "#         _, t, f = tgt_seq.shape\n",
    "        # -- Forward\n",
    "        pe_qk = self.position_enc(get_qk_encoding_table(tgt_pos, self.d_model_out).to(tgt_seq.device)).view(tgt_pos, -1)\n",
    "        pe_v = self.position_enc(get_v_encoding_table(tgt_pos, self.d_model_out).to(tgt_seq.device)).view(tgt_pos, -1)\n",
    "        dec_output_qk = tgt_seq + pe_qk\n",
    "        dec_output_v = tgt_seq + pe_v\n",
    "        dec_output, dec_slf_attn, dec_enc_attn = self.layer_stack[0](dec_output_qk, dec_output_v, \n",
    "                                                                     enc_output, slf_attn_mask_subseq)\n",
    "        if return_attns:\n",
    "                dec_slf_attn_list += [dec_slf_attn]\n",
    "                dec_enc_attn_list += [dec_enc_attn]\n",
    "                \n",
    "        for dec_layer in self.layer_stack[1:]:\n",
    "            dec_output, dec_slf_attn, dec_enc_attn = dec_layer(dec_output, dec_output, enc_output, slf_attn_mask_subseq)\n",
    "            if return_attns:\n",
    "                dec_slf_attn_list += [dec_slf_attn]\n",
    "                dec_enc_attn_list += [dec_enc_attn]\n",
    "\n",
    "        if return_attns:\n",
    "            return dec_output, dec_slf_attn_list, dec_enc_attn_list\n",
    "        return dec_output,\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    ''' A sequence to sequence model with attention mechanism. '''\n",
    "\n",
    "    def __init__(self, n_input, n_output, v, T, k_cluster,\n",
    "                 d_model_enc, d_model_dec, d_inner, n_layers,\n",
    "                 n_head_enc, n_head_dec, d_k_enc, d_v_enc, d_k_dec, d_v_dec, dropout=0.1):\n",
    "        '''\n",
    "        :param d_model_enc: dimension of encoder, always the last dimension of src sequence.\n",
    "        :param d_model_dec: dimension of decoder, always the last dimension of tgt sequence.\n",
    "        :param d_inner: the latent dimension of FF sublayer.\n",
    "        :param n_layers: the number of encoder or decoder layers.\n",
    "        :param n_head_enc: the number of encoder heads.\n",
    "        :param n_head_dec: the number of decoder heads.\n",
    "        :param d_k_enc: equal to d_model_enc / n_head_enc.\n",
    "        :param d_v_enc: equal to d_model_enc / n_head_enc.\n",
    "        :param d_k_dec: equal to d_model_dec / n_head_dec.\n",
    "        :param d_v_dec: equal to d_model_dec / n_head_dec.\n",
    "        :param dropout: dropout, default is None.\n",
    "        '''\n",
    "\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(n_input=n_input, n_output=n_output, v=v, T=T, k_cluster=k_cluster,\n",
    "                               d_model=d_model_enc, d_inner=d_inner,\n",
    "                               n_layers=n_layers, n_head=n_head_enc, d_k=d_k_enc, d_v=d_v_enc,\n",
    "                               dropout=dropout)\n",
    "\n",
    "        self.decoder = Decoder(d_model_in=d_model_enc,d_model_out=d_model_dec, d_inner=d_inner,\n",
    "                               n_layers=n_layers, n_head=n_head_dec, d_k=d_k_dec, d_v=d_v_dec,\n",
    "                               dropout=dropout)\n",
    "\n",
    "    def forward(self, src_seq, tgt_seq, graph):\n",
    "        src_pos = src_seq.size()[-2]\n",
    "        tgt_pos = tgt_seq.size()[-2]\n",
    "        enc_output, cluster, *_ = self.encoder(src_seq, src_pos, graph)\n",
    "        dec_output, *_ = self.decoder(tgt_seq, tgt_pos, enc_output)\n",
    "        return dec_output.view(-1, tgt_pos, dec_output.size(2)), cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pickle.load(open(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pickle.load(open('/nfs/project/cache_rec/data/19data/bj19_demand.pkl', 'rb'), encoding='iso-8895-1')\n",
    "data = np.array(data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "euc_graph = pickle.load(open('/nfs/project/cache_rec/graph/bj_L_euc.pkl', 'rb'), encoding='iso-8895-1')\n",
    "graph = torch.Tensor(euc_graph[0]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 6., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 4., 1., 2.],\n",
       "       [0., 4., 0., ..., 8., 3., 1.],\n",
       "       [1., 5., 1., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "\n",
    "# GCN\n",
    "b ,v = data.shape[0], data.shape[1] * data.shape[2]\n",
    "n_block = 2\n",
    "n_output = n_input = 1\n",
    "k_cluster = 5\n",
    "\n",
    "#Transformer\n",
    "d_model_enc = v * n_output\n",
    "d_model_dec = v \n",
    "d_inner = 200\n",
    "n_layers = 3\n",
    "n_head_enc = 9\n",
    "n_head_dec = 9\n",
    "d_k_enc = d_v_enc = 144\n",
    "d_k_dec = d_v_dec = 144 \n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "\n",
    "batch_size = 100\n",
    "x_length = 2*48\n",
    "y_length = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = ClusterBlock(n_input, n_output, v ,T, k_cluster).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build model.\n",
    "model = Transformer(n_input = n_input, \n",
    "                n_output = n_output, \n",
    "                v = v, \n",
    "                T = x_length, \n",
    "                k_cluster = k_cluster, \n",
    "                d_model_enc = d_model_enc, \n",
    "                d_model_dec = d_model_dec, \n",
    "                d_inner = d_inner, \n",
    "                n_layers = n_layers, \n",
    "                n_head_enc = n_head_enc, \n",
    "                n_head_dec = n_head_dec, \n",
    "                d_k_enc = d_k_enc, \n",
    "                d_v_enc = d_v_enc,\n",
    "                d_k_dec = d_k_dec, \n",
    "                d_v_dec = d_v_dec).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class linearNormalizer(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,X):\n",
    "        self._min = X.min()\n",
    "        self._max = X.max()\n",
    "#         print(('min:', self._min, 'max:', self._max))\n",
    "        \n",
    "    def transform(self,X,max_limit=500):\n",
    "        X[X>max_limit]=max_limit\n",
    "        X = (X-self._min)/(max_limit-self._min)\n",
    "        return X\n",
    "    \n",
    "    def fit_transform(self,X):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def inverse_transform(self,X):\n",
    "        X = X*(self._max-self._min)+self._min\n",
    "        return X\n",
    "    \n",
    "    def real_loss(self,loss):\n",
    "        X = X*(self._max-self._min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, data):\n",
    "        self.start = 0\n",
    "        self.data = np.array(data)\n",
    "\n",
    "    def load_batch(self, lx, ly, batch_size):\n",
    "        if self.start == 0:\n",
    "            self.start += lx\n",
    "        end = self.start + batch_size\n",
    "        if end > len(self.data) - ly + 1:\n",
    "            end = len(self.data) - ly + 1\n",
    "        x = []; y = []\n",
    "        for i in range(self.start, end):\n",
    "            x.append(self.data[i - lx:i].reshape(lx, -1))\n",
    "            y.append(self.data[i: i + ly].reshape(ly, -1))\n",
    "#         print(np.array(x).shape, np.array(y).shape, self.start)\n",
    "        x = np.array(x).swapaxes(1, 2)[:, :, :, np.newaxis]\n",
    "        y = np.array(y)\n",
    "        self.start += batch_size\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(data[:int(b*0.8)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "step = (b - v- 1) // 2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss Function and optimizer\n",
    "import itertools\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.SmoothL1Loss()\n",
    "\n",
    "def rmse(yhat,y):\n",
    "    return torch.sqrt(torch.mean((yhat-y)**2))\n",
    "\n",
    "def matrix_distance(A,B):\n",
    "    D = A - B\n",
    "    return torch.mean(D**2) \n",
    "def cluster_distance(m_list):\n",
    "    p = list(itertools.combinations(m_list,2))\n",
    "    res = []\n",
    "    for item in p:\n",
    "        res_item = matrix_distance(item[0], item[1])\n",
    "        res.append(res_item)\n",
    "    res = torch.Tensor(res) \n",
    "    return torch.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "euc_graph = pickle.load(open('/nfs/project/cache_rec/graph/bj_L_euc.pkl', 'rb'), encoding='iso-8895-1')\n",
    "graph = torch.Tensor(euc_graph[0]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape: torch.Size([100, 1296, 96, 1])\n",
      "labels shape: torch.Size([100, 1, 1296])\n",
      "output shape torch.Size([100, 1, 1296])\n",
      "Epoch [1/50] , train_loss: 15.980808 ..\n",
      "inputs shape: torch.Size([100, 1296, 96, 1])\n",
      "labels shape: torch.Size([100, 1, 1296])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 47.50 MiB (GPU 0; 8.00 GiB total capacity; 5.81 GiB already allocated; 21.86 MiB free; 125.59 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-de9e23e17249>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'labels shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-1e1fa14c7b47>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src_seq, tgt_seq, graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mtgt_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mdec_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdec_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-1e1fa14c7b47>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt_seq, tgt_pos, enc_output, return_attns)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdec_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_stack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mdec_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_slf_attn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslf_attn_mask_subseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_attns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mdec_slf_attn_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdec_slf_attn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-d032a05eeec4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, dec_input_qk, dec_input_v, enc_output, slf_attn_mask)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_input_qk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_input_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslf_attn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdec_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_slf_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslf_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_input_qk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_input_qk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_input_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslf_attn_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mdec_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mdec_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_ffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdec_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_slf_attn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-86f6f2d04bb6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_qs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_ks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_vs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_k\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (n*b) x lq x dk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 47.50 MiB (GPU 0; 8.00 GiB total capacity; 5.81 GiB already allocated; 21.86 MiB free; 125.59 MiB cached)"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):  \n",
    "    for i in range(step):\n",
    "        # Load data and transfer to GPU\n",
    "        inputs, labels = train_loader.load_batch(x_length, y_length, batch_size)\n",
    "        inputs = torch.Tensor(inputs).to(device)\n",
    "        labels = torch.Tensor(labels).to(device)\n",
    "        print(\"inputs shape:\", inputs.shape )\n",
    "        print('labels shape:', labels.shape)\n",
    "        #forward pass \n",
    "        outputs, cluster = model(inputs, labels , graph)\n",
    "        print('output shape', outputs.shape)\n",
    "        \n",
    "        # data loss  & cluster loss \n",
    "        a = criterion(outputs, labels) \n",
    "        b = cluster_distance(cluster)\n",
    "        loss = a +b \n",
    "        \n",
    "        print(\"Epoch [{}/{}] , train_loss: {:.6f} ..\".format(epoch+1, num_epochs, loss.item()))\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
