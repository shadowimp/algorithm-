{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = {'hello':0 , 'world':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([word['hello']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed= nn.Embedding(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3250,  0.2561, -1.7020,  1.1529,  0.0402]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 压缩f 的维度从5到1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(10 , 48  , 5) #  v ,t , f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.view(10, -1)    #  v , t  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 240])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7359],\n",
       "         [-0.4803],\n",
       "         [-0.0638],\n",
       "         [-0.1721],\n",
       "         [-0.7736],\n",
       "         [-0.5871],\n",
       "         [ 0.2417],\n",
       "         [ 0.0346],\n",
       "         [-0.3177],\n",
       "         [ 0.0943],\n",
       "         [ 0.6796],\n",
       "         [-0.0186],\n",
       "         [ 0.3742],\n",
       "         [-0.0137],\n",
       "         [-0.4687],\n",
       "         [ 0.0780],\n",
       "         [ 0.0357],\n",
       "         [ 0.2639],\n",
       "         [-0.0762],\n",
       "         [-0.0437],\n",
       "         [ 0.0804],\n",
       "         [ 0.0214],\n",
       "         [-0.0719],\n",
       "         [ 0.0975],\n",
       "         [ 0.2019],\n",
       "         [ 0.4120],\n",
       "         [ 0.1093],\n",
       "         [ 0.2847],\n",
       "         [ 0.0528],\n",
       "         [-0.0842],\n",
       "         [ 0.1184],\n",
       "         [-0.1976],\n",
       "         [-0.2232],\n",
       "         [-0.5953],\n",
       "         [-0.2085],\n",
       "         [-0.2552],\n",
       "         [-0.0719],\n",
       "         [-0.7749],\n",
       "         [-0.4057],\n",
       "         [-0.3374],\n",
       "         [ 0.3988],\n",
       "         [-0.3046],\n",
       "         [ 0.0658],\n",
       "         [ 0.2916],\n",
       "         [-0.2568],\n",
       "         [-0.2850],\n",
       "         [ 0.5935],\n",
       "         [ 0.0039]],\n",
       "\n",
       "        [[-0.3232],\n",
       "         [-0.6158],\n",
       "         [-0.0821],\n",
       "         [ 0.0208],\n",
       "         [-0.5416],\n",
       "         [-0.8453],\n",
       "         [ 0.1355],\n",
       "         [ 0.3232],\n",
       "         [ 0.2138],\n",
       "         [ 0.0861],\n",
       "         [ 0.2423],\n",
       "         [-0.2400],\n",
       "         [ 0.3209],\n",
       "         [-0.0460],\n",
       "         [-0.3747],\n",
       "         [-0.2008],\n",
       "         [-0.0332],\n",
       "         [ 0.3017],\n",
       "         [ 0.0751],\n",
       "         [-0.2758],\n",
       "         [ 0.1431],\n",
       "         [ 0.1426],\n",
       "         [-0.1308],\n",
       "         [-0.0094],\n",
       "         [ 0.0353],\n",
       "         [ 0.2778],\n",
       "         [-0.1111],\n",
       "         [ 0.5026],\n",
       "         [ 0.0761],\n",
       "         [ 0.1685],\n",
       "         [ 0.1379],\n",
       "         [-0.3582],\n",
       "         [-0.2139],\n",
       "         [-0.4343],\n",
       "         [-0.7064],\n",
       "         [-0.2071],\n",
       "         [-0.0776],\n",
       "         [-0.4980],\n",
       "         [ 0.3787],\n",
       "         [-0.3345],\n",
       "         [ 0.7939],\n",
       "         [-0.0255],\n",
       "         [-0.1757],\n",
       "         [ 0.1889],\n",
       "         [-0.0481],\n",
       "         [-0.2865],\n",
       "         [ 0.2828],\n",
       "         [ 0.3269]],\n",
       "\n",
       "        [[-0.3613],\n",
       "         [-0.4544],\n",
       "         [ 0.2506],\n",
       "         [-0.1641],\n",
       "         [-0.5046],\n",
       "         [-0.8354],\n",
       "         [ 0.3147],\n",
       "         [ 0.1925],\n",
       "         [ 0.1446],\n",
       "         [-0.1695],\n",
       "         [ 0.3210],\n",
       "         [-0.2620],\n",
       "         [ 0.1656],\n",
       "         [-0.0485],\n",
       "         [-0.5770],\n",
       "         [-0.2310],\n",
       "         [-0.2008],\n",
       "         [ 0.2777],\n",
       "         [-0.0261],\n",
       "         [-0.2339],\n",
       "         [ 0.3970],\n",
       "         [ 0.0428],\n",
       "         [-0.1536],\n",
       "         [ 0.3326],\n",
       "         [-0.0089],\n",
       "         [ 0.3277],\n",
       "         [-0.3711],\n",
       "         [ 0.4237],\n",
       "         [ 0.2304],\n",
       "         [ 0.1404],\n",
       "         [-0.2190],\n",
       "         [-0.2725],\n",
       "         [-0.4218],\n",
       "         [-0.3917],\n",
       "         [-0.4764],\n",
       "         [-0.4165],\n",
       "         [ 0.0493],\n",
       "         [-0.6143],\n",
       "         [-0.1031],\n",
       "         [-0.4822],\n",
       "         [ 0.7964],\n",
       "         [ 0.1423],\n",
       "         [-0.0482],\n",
       "         [ 0.2314],\n",
       "         [ 0.0809],\n",
       "         [-0.3048],\n",
       "         [ 0.1474],\n",
       "         [ 0.2704]],\n",
       "\n",
       "        [[-0.1150],\n",
       "         [-0.2874],\n",
       "         [ 0.3548],\n",
       "         [ 0.0895],\n",
       "         [-1.1120],\n",
       "         [-0.7067],\n",
       "         [-0.0144],\n",
       "         [ 0.2662],\n",
       "         [ 0.1761],\n",
       "         [ 0.0700],\n",
       "         [ 0.4270],\n",
       "         [-0.1238],\n",
       "         [ 0.3852],\n",
       "         [-0.1633],\n",
       "         [-0.5258],\n",
       "         [ 0.0612],\n",
       "         [-0.2829],\n",
       "         [ 0.1023],\n",
       "         [-0.0319],\n",
       "         [-0.3697],\n",
       "         [ 0.3822],\n",
       "         [ 0.1360],\n",
       "         [-0.2557],\n",
       "         [ 0.2524],\n",
       "         [ 0.1407],\n",
       "         [ 0.0902],\n",
       "         [-0.0664],\n",
       "         [ 0.1772],\n",
       "         [-0.0848],\n",
       "         [-0.1517],\n",
       "         [ 0.0511],\n",
       "         [-0.0683],\n",
       "         [-0.4790],\n",
       "         [-0.6242],\n",
       "         [-0.4822],\n",
       "         [-0.3210],\n",
       "         [ 0.0321],\n",
       "         [-0.4948],\n",
       "         [ 0.0809],\n",
       "         [-0.2690],\n",
       "         [ 0.6737],\n",
       "         [-0.1479],\n",
       "         [-0.1681],\n",
       "         [ 0.0487],\n",
       "         [-0.0014],\n",
       "         [-0.3228],\n",
       "         [ 0.2474],\n",
       "         [ 0.1446]],\n",
       "\n",
       "        [[-0.4117],\n",
       "         [-0.6154],\n",
       "         [-0.0828],\n",
       "         [-0.0676],\n",
       "         [-0.8000],\n",
       "         [-0.4590],\n",
       "         [ 0.0976],\n",
       "         [ 0.0716],\n",
       "         [ 0.1669],\n",
       "         [ 0.1667],\n",
       "         [ 0.3235],\n",
       "         [-0.0226],\n",
       "         [ 0.6916],\n",
       "         [-0.2435],\n",
       "         [-0.6575],\n",
       "         [-0.1089],\n",
       "         [-0.5450],\n",
       "         [ 0.3184],\n",
       "         [-0.1415],\n",
       "         [-0.1741],\n",
       "         [ 0.1602],\n",
       "         [-0.0893],\n",
       "         [-0.1348],\n",
       "         [-0.1708],\n",
       "         [-0.0692],\n",
       "         [ 0.3424],\n",
       "         [-0.1425],\n",
       "         [ 0.1369],\n",
       "         [ 0.2200],\n",
       "         [-0.0466],\n",
       "         [-0.0675],\n",
       "         [-0.2448],\n",
       "         [-0.3290],\n",
       "         [-0.4866],\n",
       "         [-0.4448],\n",
       "         [-0.3578],\n",
       "         [-0.0912],\n",
       "         [-1.0061],\n",
       "         [-0.2101],\n",
       "         [-0.4991],\n",
       "         [ 0.5197],\n",
       "         [ 0.2105],\n",
       "         [ 0.1759],\n",
       "         [ 0.0674],\n",
       "         [ 0.1828],\n",
       "         [-0.5034],\n",
       "         [ 0.3758],\n",
       "         [ 0.0042]],\n",
       "\n",
       "        [[-0.2608],\n",
       "         [-0.6408],\n",
       "         [-0.2579],\n",
       "         [-0.1528],\n",
       "         [-0.7803],\n",
       "         [-0.6981],\n",
       "         [ 0.3790],\n",
       "         [-0.0743],\n",
       "         [ 0.1726],\n",
       "         [-0.0057],\n",
       "         [ 0.1443],\n",
       "         [-0.6061],\n",
       "         [ 0.3099],\n",
       "         [-0.0680],\n",
       "         [-0.4126],\n",
       "         [-0.0851],\n",
       "         [-0.1875],\n",
       "         [ 0.2854],\n",
       "         [ 0.0375],\n",
       "         [-0.4899],\n",
       "         [ 0.4777],\n",
       "         [ 0.2514],\n",
       "         [-0.1858],\n",
       "         [ 0.3965],\n",
       "         [ 0.0915],\n",
       "         [ 0.0738],\n",
       "         [-0.1192],\n",
       "         [ 0.3054],\n",
       "         [ 0.3160],\n",
       "         [-0.1727],\n",
       "         [ 0.1416],\n",
       "         [-0.4014],\n",
       "         [-0.4259],\n",
       "         [-0.7409],\n",
       "         [-0.5260],\n",
       "         [-0.4457],\n",
       "         [-0.0571],\n",
       "         [-0.7941],\n",
       "         [-0.3811],\n",
       "         [-0.5592],\n",
       "         [ 0.5386],\n",
       "         [-0.1868],\n",
       "         [ 0.0604],\n",
       "         [-0.1642],\n",
       "         [ 0.0534],\n",
       "         [-0.5707],\n",
       "         [ 0.4645],\n",
       "         [-0.3488]],\n",
       "\n",
       "        [[-0.7931],\n",
       "         [-0.4643],\n",
       "         [ 0.3184],\n",
       "         [ 0.5427],\n",
       "         [-0.6716],\n",
       "         [-0.6720],\n",
       "         [ 0.1747],\n",
       "         [ 0.5474],\n",
       "         [ 0.1695],\n",
       "         [-0.1128],\n",
       "         [ 0.3913],\n",
       "         [-0.2346],\n",
       "         [ 0.4358],\n",
       "         [-0.0095],\n",
       "         [-0.6219],\n",
       "         [-0.1747],\n",
       "         [ 0.3178],\n",
       "         [ 0.3776],\n",
       "         [-0.0731],\n",
       "         [-0.2579],\n",
       "         [ 0.3983],\n",
       "         [ 0.0381],\n",
       "         [-0.2553],\n",
       "         [ 0.1303],\n",
       "         [ 0.3212],\n",
       "         [ 0.1605],\n",
       "         [-0.0758],\n",
       "         [ 0.1987],\n",
       "         [ 0.0203],\n",
       "         [ 0.2813],\n",
       "         [-0.1431],\n",
       "         [-0.3707],\n",
       "         [ 0.0508],\n",
       "         [-0.5232],\n",
       "         [-0.5696],\n",
       "         [-0.5152],\n",
       "         [-0.0116],\n",
       "         [-0.7181],\n",
       "         [ 0.0638],\n",
       "         [-0.5759],\n",
       "         [ 0.7129],\n",
       "         [-0.0205],\n",
       "         [-0.0373],\n",
       "         [ 0.1098],\n",
       "         [-0.2554],\n",
       "         [-0.4218],\n",
       "         [ 0.2534],\n",
       "         [ 0.0638]],\n",
       "\n",
       "        [[-0.3741],\n",
       "         [-0.4812],\n",
       "         [-0.0644],\n",
       "         [-0.1088],\n",
       "         [-0.8384],\n",
       "         [-0.5544],\n",
       "         [ 0.1393],\n",
       "         [ 0.1388],\n",
       "         [ 0.3213],\n",
       "         [-0.1107],\n",
       "         [ 0.2080],\n",
       "         [-0.0439],\n",
       "         [ 0.4657],\n",
       "         [-0.2003],\n",
       "         [-0.4443],\n",
       "         [-0.0601],\n",
       "         [-0.1674],\n",
       "         [ 0.3347],\n",
       "         [ 0.0322],\n",
       "         [-0.3531],\n",
       "         [-0.2544],\n",
       "         [ 0.0429],\n",
       "         [-0.4132],\n",
       "         [ 0.0662],\n",
       "         [ 0.0659],\n",
       "         [ 0.3629],\n",
       "         [ 0.0794],\n",
       "         [ 0.4719],\n",
       "         [ 0.1579],\n",
       "         [-0.0091],\n",
       "         [ 0.2998],\n",
       "         [-0.3339],\n",
       "         [-0.0902],\n",
       "         [-0.5220],\n",
       "         [-0.7150],\n",
       "         [-0.4293],\n",
       "         [-0.0782],\n",
       "         [-1.0268],\n",
       "         [-0.0689],\n",
       "         [-0.4772],\n",
       "         [ 0.6389],\n",
       "         [ 0.0013],\n",
       "         [-0.0104],\n",
       "         [ 0.3027],\n",
       "         [ 0.0747],\n",
       "         [-0.3969],\n",
       "         [ 0.5942],\n",
       "         [ 0.3394]],\n",
       "\n",
       "        [[-0.5809],\n",
       "         [-0.3095],\n",
       "         [-0.0314],\n",
       "         [ 0.2381],\n",
       "         [-0.7250],\n",
       "         [-0.8653],\n",
       "         [-0.3485],\n",
       "         [ 0.2630],\n",
       "         [ 0.0886],\n",
       "         [-0.0087],\n",
       "         [ 0.2329],\n",
       "         [-0.2448],\n",
       "         [ 0.6239],\n",
       "         [ 0.0203],\n",
       "         [-0.5833],\n",
       "         [-0.1463],\n",
       "         [-0.1319],\n",
       "         [ 0.2341],\n",
       "         [-0.0795],\n",
       "         [-0.1278],\n",
       "         [ 0.3670],\n",
       "         [ 0.2650],\n",
       "         [ 0.0990],\n",
       "         [ 0.1169],\n",
       "         [-0.0887],\n",
       "         [ 0.5178],\n",
       "         [ 0.1233],\n",
       "         [ 0.2305],\n",
       "         [ 0.0209],\n",
       "         [ 0.0820],\n",
       "         [ 0.1818],\n",
       "         [-0.4168],\n",
       "         [-0.3286],\n",
       "         [-0.9588],\n",
       "         [-0.7388],\n",
       "         [-0.4222],\n",
       "         [-0.1192],\n",
       "         [-0.7106],\n",
       "         [-0.2499],\n",
       "         [-0.6272],\n",
       "         [ 0.9215],\n",
       "         [ 0.0433],\n",
       "         [ 0.1666],\n",
       "         [ 0.2578],\n",
       "         [-0.2173],\n",
       "         [-0.0761],\n",
       "         [ 0.5760],\n",
       "         [-0.0662]],\n",
       "\n",
       "        [[-0.1901],\n",
       "         [-0.3335],\n",
       "         [ 0.0132],\n",
       "         [ 0.1804],\n",
       "         [-0.5101],\n",
       "         [-0.6840],\n",
       "         [ 0.0894],\n",
       "         [ 0.2889],\n",
       "         [ 0.1254],\n",
       "         [ 0.4430],\n",
       "         [ 0.5365],\n",
       "         [-0.2628],\n",
       "         [ 0.4660],\n",
       "         [-0.1646],\n",
       "         [-0.3327],\n",
       "         [-0.3151],\n",
       "         [-0.0645],\n",
       "         [ 0.2500],\n",
       "         [ 0.2094],\n",
       "         [-0.3386],\n",
       "         [ 0.2120],\n",
       "         [ 0.0835],\n",
       "         [-0.2726],\n",
       "         [ 0.3054],\n",
       "         [ 0.0144],\n",
       "         [ 0.2517],\n",
       "         [ 0.0036],\n",
       "         [ 0.2105],\n",
       "         [ 0.0395],\n",
       "         [-0.2588],\n",
       "         [ 0.1383],\n",
       "         [ 0.3490],\n",
       "         [-0.2710],\n",
       "         [-0.6216],\n",
       "         [-0.6104],\n",
       "         [-0.3464],\n",
       "         [ 0.1873],\n",
       "         [-0.7456],\n",
       "         [-0.3659],\n",
       "         [-0.5888],\n",
       "         [ 0.6829],\n",
       "         [-0.1903],\n",
       "         [ 0.2573],\n",
       "         [ 0.0716],\n",
       "         [ 0.0530],\n",
       "         [-0.1514],\n",
       "         [ 0.3903],\n",
       "         [ 0.2973]]], grad_fn=<AsStridedBackward>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear1 = nn.Linear(240 , 48)\n",
    "output = linear1(data)\n",
    "output.reshape(10,48 ,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数标准化 uniform_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1.5414e-44, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], requires_grad=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.parameter import Parameter\n",
    "p1 = Parameter(torch.FloatTensor(4, 4))\n",
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4155, -0.2765, -0.1535,  0.3942],\n",
       "        [ 0.1942, -0.2998, -0.4919,  0.2088],\n",
       "        [-0.3870, -0.0095,  0.1049, -0.1374],\n",
       "        [ 0.4452,  0.2468,  0.3518, -0.4824]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.data.uniform_(-0.5 , 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2059, -0.1564, -0.0084,  0.0633],\n",
       "        [-0.0487, -0.3821,  0.4888, -0.2574],\n",
       "        [-0.0788,  0.4098, -0.1890, -0.3871],\n",
       "        [-0.2003, -0.2328, -0.1334, -0.1029]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "weight = Parameter(torch.FloatTensor(4, 4))\n",
    "stdv = 1. / math.sqrt(weight.size(1))\n",
    "weight.data.uniform_(-stdv, stdv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 定义参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.param = nn.Parameter(torch.rand(3,3)) \n",
    "        # 等价与self.register_parameter('param1' ,nn.Parameter(t.randn(3, 3)))\n",
    "    def forward(self,input):\n",
    "        x = self.param.mm(input)\n",
    "        return x \n",
    "n = Net()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.register_parameter('param',nn.Parameter(torch.randn(3, 3)))\n",
    "    def forward(self,input):\n",
    "        x = self.param.mm(input)\n",
    "        return x \n",
    "n = Net()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cluster gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.randint(3, 5, (10,2))  # n , k\n",
    "w = torch.randint(3, 5, (2,3,4)) #  k , f1, f2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.mm(c,w.view(2,-1)) # n , f1*f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 4])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.view(10,3,4).shape # n , f1 , f2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = nn.Parameter(torch.rand(10,2,3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "con1 = nn.Conv2d(1, 1, 16) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw( c , w):\n",
    "    \"\"\"\n",
    "    input:  \n",
    "    output : w of clustered \n",
    "    \"\"\"\n",
    "    CW = []\n",
    "    for i in range(c.shape[0]):\n",
    "        w_i = c[i][0] * w[0] + c[i][1]*w[1] + c[i][2] *w[2] \n",
    "        CW.append(w_i)\n",
    "    return CW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.rand(10 ,3 )  # v , k \n",
    "w = torch.rand(3,2,2)  # v , f1, f2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### soft cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = nn.Linear(5 , 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4,2, 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear1(x).view(4,2,3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3, 5])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 矩阵间的欧式距离\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1000,  0.1000],\n",
       "        [ 0.1000, -0.1000]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.Tensor( [[0.1 , 0.9], [0.2,0.8]] ) \n",
    "B = torch.Tensor([[0.2 , 0.8], [0.1,0.9] ])\n",
    "C = torch.Tensor([[0.1 , 0.9], [0.2,0.8] ])\n",
    "C = A - B \n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0400)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(C**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_distance(A,B):\n",
    "    D = A - B\n",
    "    return torch.sum( D**2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 排列组合\n",
    "import itertools\n",
    "list(itertools.permutations([1,2,3,4],2))\n",
    "list(itertools.combinations([1,2,3,4],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[0.1000, 0.9000],\n",
       "          [0.2000, 0.8000]]), tensor([[0.2000, 0.8000],\n",
       "          [0.1000, 0.9000]])), (tensor([[0.1000, 0.9000],\n",
       "          [0.2000, 0.8000]]), tensor([[0.1000, 0.9000],\n",
       "          [0.2000, 0.8000]])), (tensor([[0.2000, 0.8000],\n",
       "          [0.1000, 0.9000]]), tensor([[0.1000, 0.9000],\n",
       "          [0.2000, 0.8000]]))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.Tensor( [[0.1 , 0.9], [0.2,0.8]] ) \n",
    "B = torch.Tensor([[0.2 , 0.8], [0.1,0.9] ])\n",
    "C = torch.Tensor([[0.1 , 0.9], [0.2,0.8] ])\n",
    "D = torch.Tensor([[0.3 , 0.7], [0.6,0.4] ])\n",
    "list(itertools.combinations([A , B , C],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_distance(A,B):\n",
    "    D = A - B\n",
    "    return torch.sum(D**2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def cluster_distance(m_list):\n",
    "    p = list(itertools.combinations(m_list,2))\n",
    "    res = 0 \n",
    "    for item in p:\n",
    "        res_item = matrix_distance(item[0] , item[1])\n",
    "        res += res_item\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_distance([A,B,C,D])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "train_dataset = torch.rand(50, 10 , 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=10, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([10, 10, 5])\n",
      "1 torch.Size([10, 10, 5])\n",
      "2 torch.Size([10, 10, 5])\n",
      "3 torch.Size([10, 10, 5])\n",
      "4 torch.Size([10, 10, 5])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_loader): \n",
    "    print(i,data.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### cluster distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def matrix_distance(A,B):\n",
    "    D = A - B\n",
    "    return torch.mean(D**2) \n",
    "def cluster_distance(m_list):\n",
    "    p = list(itertools.combinations(m_list,2))\n",
    "    res = []\n",
    "    for item in p:\n",
    "        res_item = matrix_distance(item[0] , item[1])\n",
    "        res.append(res_item)\n",
    "        res = torch.Tensor( res ) \n",
    "    return torch.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.Tensor( [[0.1 , 0.9], [0.2,0.8]] ) \n",
    "B = torch.Tensor([[0.2 , 0.8], [0.1,0.9] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0100)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_distance([A,B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### graph to batch graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2., 3.],\n",
      "         [5., 6.]],\n",
      "\n",
      "        [[2., 3.],\n",
      "         [5., 6.]]])\n"
     ]
    }
   ],
   "source": [
    "graph = torch.Tensor( [ [2,3], [5,6] ])\n",
    "graph.unsqueeze(0)\n",
    "graph = graph.repeat(2 ,1,1) \n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 软分类 to 硬分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9000, 0.1000],\n",
       "        [0.2000, 0.8000],\n",
       "        [0.8000, 0.2000],\n",
       "        [0.7000, 0.3000]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = torch.Tensor([[0.9,0.1],[0.2,0.8] , [0.8,0.2] , [0.7,0.3] ])\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9000, 0.8000, 0.8000, 0.7000])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(cluster , 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.transpose(torch.max(cluster , 1)[0].repeat(2,1),0,1)\n",
    "a = torch.ones(4,2)\n",
    "b = torch.zeros(4,2)\n",
    "torch.where(cluster-m>=0 , a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_cluster = torch.Tensor([[[0.9,0.1,0.1],[0.2,0.4,0.8] , [0.8,0.6,0.2] , [0.7,0.3,0.1]]])\n",
    "soft_cluster.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9000, 0.9000, 0.9000],\n",
       "         [0.8000, 0.8000, 0.8000],\n",
       "         [0.8000, 0.8000, 0.8000],\n",
       "         [0.7000, 0.7000, 0.7000]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_mat = torch.max(soft_cluster, -1)[0].unsqueeze(-1).repeat(1, 1, 3)\n",
    "max_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.rand([1, 4 ,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9000, 0.8000, 0.8000, 0.7000]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(soft_cluster, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(1,4,3)\n",
    "b = torch.zeros(1,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_cluster = torch.where(soft_cluster-max_mat >=0 , a , b)\n",
    "hard_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_cluster[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8020, 0.2433, 0.5654],\n",
       "         [0.7393, 0.5971, 0.2951],\n",
       "         [0.7850, 0.3613, 0.4925],\n",
       "         [0.8192, 0.9343, 0.2774]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8020, 0.2433, 0.5654],\n",
       "         [0.0000, 0.0000, 0.0000],\n",
       "         [0.7850, 0.3613, 0.4925],\n",
       "         [0.8192, 0.9343, 0.2774]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(out ,hard_cluster[:, :, 0].unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 1.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_2D = torch.FloatTensor((np.random.rand(4,4)>0.9).astype(np.int))\n",
    "graph_2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2],[3,4]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 3.],\n",
       "        [2., 4.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(x, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 3.],\n",
       "        [2., 4.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(1,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3,3, 5)\n",
    "b = torch.rand(5,1)\n",
    "torch.matmul(a,b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
