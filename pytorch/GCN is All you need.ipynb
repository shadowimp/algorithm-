{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = {'hello':0 , 'world':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([word['hello']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed= nn.Embedding(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1163,  0.0230,  0.0517, -0.7425,  0.7532]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 压缩f 的维度从5到1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(10 , 48  , 5) #  v ,t , f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.view(10, -1)    #  v , t  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 240])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3243],\n",
       "         [ 0.4059],\n",
       "         [-0.0416],\n",
       "         [-0.2535],\n",
       "         [ 0.2434],\n",
       "         [-0.1275],\n",
       "         [-0.0344],\n",
       "         [-0.0916],\n",
       "         [-0.1420],\n",
       "         [ 0.3764],\n",
       "         [ 0.3226],\n",
       "         [ 0.2982],\n",
       "         [-0.2660],\n",
       "         [ 0.1123],\n",
       "         [-0.5086],\n",
       "         [-0.0021],\n",
       "         [-0.1456],\n",
       "         [-0.0865],\n",
       "         [-0.5184],\n",
       "         [ 0.3233],\n",
       "         [-0.0279],\n",
       "         [-0.6809],\n",
       "         [-0.5108],\n",
       "         [-0.5079],\n",
       "         [ 0.2120],\n",
       "         [ 0.0464],\n",
       "         [-0.5996],\n",
       "         [ 0.7858],\n",
       "         [-0.4039],\n",
       "         [ 0.0581],\n",
       "         [-0.0894],\n",
       "         [-0.2846],\n",
       "         [ 0.2320],\n",
       "         [-0.3409],\n",
       "         [-0.5394],\n",
       "         [-0.3457],\n",
       "         [ 0.1426],\n",
       "         [-0.2314],\n",
       "         [-0.4082],\n",
       "         [-0.2788],\n",
       "         [ 0.1929],\n",
       "         [ 0.1521],\n",
       "         [ 0.1015],\n",
       "         [-0.3481],\n",
       "         [ 0.0471],\n",
       "         [-0.2082],\n",
       "         [-0.5511],\n",
       "         [-0.0266]],\n",
       "\n",
       "        [[-0.1885],\n",
       "         [ 0.2708],\n",
       "         [-0.3094],\n",
       "         [-0.3892],\n",
       "         [ 0.1200],\n",
       "         [-0.1003],\n",
       "         [-0.1901],\n",
       "         [ 0.0324],\n",
       "         [-0.1418],\n",
       "         [ 0.5913],\n",
       "         [ 0.5691],\n",
       "         [-0.0748],\n",
       "         [-0.4338],\n",
       "         [-0.2804],\n",
       "         [-0.3503],\n",
       "         [ 0.2968],\n",
       "         [ 0.0921],\n",
       "         [-0.2285],\n",
       "         [-0.0433],\n",
       "         [-0.1156],\n",
       "         [-0.1524],\n",
       "         [-0.6234],\n",
       "         [-0.2048],\n",
       "         [-0.3359],\n",
       "         [ 0.2500],\n",
       "         [ 0.0958],\n",
       "         [-0.5435],\n",
       "         [ 0.6675],\n",
       "         [-0.5195],\n",
       "         [-0.3102],\n",
       "         [ 0.1371],\n",
       "         [-0.0936],\n",
       "         [-0.0090],\n",
       "         [-0.0252],\n",
       "         [-0.3818],\n",
       "         [ 0.0325],\n",
       "         [ 0.2862],\n",
       "         [-0.3608],\n",
       "         [-0.4170],\n",
       "         [-0.2107],\n",
       "         [ 0.5587],\n",
       "         [ 0.0935],\n",
       "         [ 0.0193],\n",
       "         [-0.3062],\n",
       "         [ 0.1895],\n",
       "         [-0.0346],\n",
       "         [-0.6659],\n",
       "         [ 0.2093]],\n",
       "\n",
       "        [[-0.4274],\n",
       "         [ 0.1539],\n",
       "         [ 0.1476],\n",
       "         [-0.1324],\n",
       "         [ 0.1444],\n",
       "         [-0.1755],\n",
       "         [-0.5332],\n",
       "         [ 0.1135],\n",
       "         [ 0.0456],\n",
       "         [ 0.5259],\n",
       "         [ 0.0925],\n",
       "         [-0.1822],\n",
       "         [-0.4350],\n",
       "         [-0.1956],\n",
       "         [-0.2928],\n",
       "         [ 0.2789],\n",
       "         [ 0.2248],\n",
       "         [-0.2680],\n",
       "         [ 0.0300],\n",
       "         [-0.4635],\n",
       "         [-0.0375],\n",
       "         [-0.5591],\n",
       "         [-0.2581],\n",
       "         [-0.7830],\n",
       "         [ 0.4369],\n",
       "         [-0.1042],\n",
       "         [-0.3324],\n",
       "         [ 0.6082],\n",
       "         [-0.1741],\n",
       "         [-0.2154],\n",
       "         [-0.2661],\n",
       "         [-0.4621],\n",
       "         [-0.1467],\n",
       "         [-0.3729],\n",
       "         [-0.4417],\n",
       "         [-0.0897],\n",
       "         [ 0.4043],\n",
       "         [-0.5655],\n",
       "         [-0.3273],\n",
       "         [-0.1698],\n",
       "         [ 0.0705],\n",
       "         [ 0.0978],\n",
       "         [ 0.0710],\n",
       "         [-0.0366],\n",
       "         [ 0.4032],\n",
       "         [-0.1553],\n",
       "         [-0.3907],\n",
       "         [ 0.1205]],\n",
       "\n",
       "        [[-0.3168],\n",
       "         [ 0.4524],\n",
       "         [-0.0105],\n",
       "         [ 0.0243],\n",
       "         [ 0.1959],\n",
       "         [-0.1419],\n",
       "         [-0.4621],\n",
       "         [-0.3135],\n",
       "         [-0.3093],\n",
       "         [ 0.5378],\n",
       "         [ 0.0401],\n",
       "         [ 0.0490],\n",
       "         [-0.0808],\n",
       "         [-0.1529],\n",
       "         [-0.6298],\n",
       "         [ 0.1799],\n",
       "         [ 0.0569],\n",
       "         [ 0.1544],\n",
       "         [-0.1894],\n",
       "         [-0.0405],\n",
       "         [ 0.0464],\n",
       "         [-0.5400],\n",
       "         [-0.0256],\n",
       "         [-0.4474],\n",
       "         [ 0.3308],\n",
       "         [ 0.2002],\n",
       "         [-0.4699],\n",
       "         [ 0.4055],\n",
       "         [-0.4803],\n",
       "         [-0.3539],\n",
       "         [ 0.0371],\n",
       "         [-0.0339],\n",
       "         [-0.2196],\n",
       "         [ 0.0503],\n",
       "         [-0.2352],\n",
       "         [-0.1809],\n",
       "         [ 0.0823],\n",
       "         [-0.5072],\n",
       "         [-0.1985],\n",
       "         [-0.0973],\n",
       "         [ 0.1333],\n",
       "         [ 0.1766],\n",
       "         [-0.2781],\n",
       "         [-0.5004],\n",
       "         [ 0.2157],\n",
       "         [-0.2638],\n",
       "         [-0.7680],\n",
       "         [-0.2626]],\n",
       "\n",
       "        [[-0.3991],\n",
       "         [ 0.2621],\n",
       "         [-0.2212],\n",
       "         [-0.3850],\n",
       "         [ 0.1216],\n",
       "         [ 0.1094],\n",
       "         [-0.3022],\n",
       "         [-0.2762],\n",
       "         [-0.2395],\n",
       "         [ 0.2296],\n",
       "         [ 0.3214],\n",
       "         [-0.1604],\n",
       "         [ 0.0229],\n",
       "         [ 0.0772],\n",
       "         [-0.3178],\n",
       "         [ 0.2907],\n",
       "         [ 0.2003],\n",
       "         [-0.0181],\n",
       "         [-0.0734],\n",
       "         [-0.0599],\n",
       "         [-0.0965],\n",
       "         [-0.6226],\n",
       "         [-0.4630],\n",
       "         [-0.3318],\n",
       "         [ 0.5307],\n",
       "         [-0.1288],\n",
       "         [-0.2705],\n",
       "         [ 0.3072],\n",
       "         [-0.6620],\n",
       "         [-0.1436],\n",
       "         [ 0.3077],\n",
       "         [-0.0584],\n",
       "         [-0.3910],\n",
       "         [-0.1947],\n",
       "         [-0.3879],\n",
       "         [-0.0653],\n",
       "         [-0.0435],\n",
       "         [-0.2531],\n",
       "         [-0.0949],\n",
       "         [-0.1428],\n",
       "         [ 0.0347],\n",
       "         [ 0.2813],\n",
       "         [-0.0035],\n",
       "         [-0.2700],\n",
       "         [ 0.0580],\n",
       "         [-0.0238],\n",
       "         [-0.5813],\n",
       "         [ 0.2695]],\n",
       "\n",
       "        [[-0.5692],\n",
       "         [ 0.3088],\n",
       "         [-0.3799],\n",
       "         [-0.1787],\n",
       "         [ 0.2906],\n",
       "         [-0.2664],\n",
       "         [-0.3917],\n",
       "         [ 0.0723],\n",
       "         [ 0.1630],\n",
       "         [ 0.7666],\n",
       "         [-0.2378],\n",
       "         [ 0.0285],\n",
       "         [-0.4680],\n",
       "         [-0.0881],\n",
       "         [-0.4253],\n",
       "         [-0.0683],\n",
       "         [ 0.4360],\n",
       "         [ 0.0828],\n",
       "         [-0.0328],\n",
       "         [-0.4225],\n",
       "         [-0.0644],\n",
       "         [-0.6752],\n",
       "         [-0.2994],\n",
       "         [-0.5184],\n",
       "         [ 0.4019],\n",
       "         [-0.0034],\n",
       "         [-0.2907],\n",
       "         [ 0.3450],\n",
       "         [-0.5023],\n",
       "         [-0.1319],\n",
       "         [-0.0168],\n",
       "         [-0.3045],\n",
       "         [-0.2206],\n",
       "         [-0.1684],\n",
       "         [-0.1601],\n",
       "         [-0.0704],\n",
       "         [ 0.3459],\n",
       "         [-0.5258],\n",
       "         [-0.2417],\n",
       "         [ 0.1087],\n",
       "         [ 0.1335],\n",
       "         [ 0.3867],\n",
       "         [ 0.1521],\n",
       "         [-0.2402],\n",
       "         [ 0.4844],\n",
       "         [-0.0416],\n",
       "         [-0.6690],\n",
       "         [ 0.1183]],\n",
       "\n",
       "        [[-0.3227],\n",
       "         [ 0.5431],\n",
       "         [ 0.1426],\n",
       "         [-0.2254],\n",
       "         [ 0.3814],\n",
       "         [ 0.0611],\n",
       "         [-0.1665],\n",
       "         [ 0.0636],\n",
       "         [-0.0702],\n",
       "         [ 0.6879],\n",
       "         [ 0.1203],\n",
       "         [ 0.2466],\n",
       "         [-0.1269],\n",
       "         [-0.0646],\n",
       "         [-0.3971],\n",
       "         [-0.0736],\n",
       "         [-0.0437],\n",
       "         [ 0.1970],\n",
       "         [ 0.3015],\n",
       "         [-0.0500],\n",
       "         [-0.2959],\n",
       "         [-0.4259],\n",
       "         [-0.3525],\n",
       "         [-0.3509],\n",
       "         [ 0.5400],\n",
       "         [ 0.1307],\n",
       "         [-0.3695],\n",
       "         [ 0.7773],\n",
       "         [-0.5866],\n",
       "         [-0.2044],\n",
       "         [-0.1536],\n",
       "         [-0.0710],\n",
       "         [-0.0803],\n",
       "         [ 0.2074],\n",
       "         [-0.4706],\n",
       "         [ 0.1293],\n",
       "         [-0.1777],\n",
       "         [-0.3326],\n",
       "         [-0.2014],\n",
       "         [-0.5357],\n",
       "         [ 0.2180],\n",
       "         [ 0.0827],\n",
       "         [ 0.2667],\n",
       "         [-0.4451],\n",
       "         [ 0.1975],\n",
       "         [-0.2139],\n",
       "         [-0.8484],\n",
       "         [ 0.1646]],\n",
       "\n",
       "        [[-0.1494],\n",
       "         [ 0.0610],\n",
       "         [-0.1257],\n",
       "         [-0.2204],\n",
       "         [ 0.0930],\n",
       "         [ 0.1161],\n",
       "         [-0.2619],\n",
       "         [ 0.1710],\n",
       "         [ 0.0971],\n",
       "         [ 0.3714],\n",
       "         [ 0.0674],\n",
       "         [ 0.1227],\n",
       "         [-0.2179],\n",
       "         [-0.0426],\n",
       "         [-0.1428],\n",
       "         [-0.1228],\n",
       "         [ 0.1813],\n",
       "         [ 0.0016],\n",
       "         [-0.0394],\n",
       "         [ 0.0865],\n",
       "         [-0.1374],\n",
       "         [-0.3259],\n",
       "         [-0.3173],\n",
       "         [-0.5186],\n",
       "         [ 0.4649],\n",
       "         [ 0.0530],\n",
       "         [-0.5324],\n",
       "         [ 0.3575],\n",
       "         [-0.4901],\n",
       "         [-0.3021],\n",
       "         [ 0.0658],\n",
       "         [-0.3121],\n",
       "         [-0.0556],\n",
       "         [-0.2519],\n",
       "         [-0.4541],\n",
       "         [-0.1079],\n",
       "         [-0.0802],\n",
       "         [-0.5444],\n",
       "         [-0.2514],\n",
       "         [-0.1053],\n",
       "         [ 0.2689],\n",
       "         [ 0.1578],\n",
       "         [ 0.0246],\n",
       "         [ 0.0570],\n",
       "         [ 0.3665],\n",
       "         [-0.2358],\n",
       "         [-0.8478],\n",
       "         [-0.3928]],\n",
       "\n",
       "        [[-0.1186],\n",
       "         [ 0.1548],\n",
       "         [ 0.1838],\n",
       "         [-0.0760],\n",
       "         [ 0.3072],\n",
       "         [ 0.1435],\n",
       "         [-0.3373],\n",
       "         [ 0.0676],\n",
       "         [-0.1569],\n",
       "         [ 0.4462],\n",
       "         [-0.0188],\n",
       "         [-0.0506],\n",
       "         [-0.4089],\n",
       "         [-0.3066],\n",
       "         [-0.6684],\n",
       "         [ 0.1940],\n",
       "         [ 0.1741],\n",
       "         [-0.1290],\n",
       "         [ 0.1205],\n",
       "         [ 0.1794],\n",
       "         [-0.0676],\n",
       "         [-0.8239],\n",
       "         [-0.3707],\n",
       "         [-0.3019],\n",
       "         [ 0.7978],\n",
       "         [-0.2703],\n",
       "         [-0.5610],\n",
       "         [ 0.2363],\n",
       "         [-0.8044],\n",
       "         [ 0.0876],\n",
       "         [-0.0510],\n",
       "         [-0.1452],\n",
       "         [-0.2406],\n",
       "         [ 0.0827],\n",
       "         [-0.5628],\n",
       "         [-0.3617],\n",
       "         [ 0.0882],\n",
       "         [-0.4371],\n",
       "         [-0.1373],\n",
       "         [-0.3463],\n",
       "         [ 0.2408],\n",
       "         [ 0.2858],\n",
       "         [-0.1483],\n",
       "         [-0.1386],\n",
       "         [ 0.3618],\n",
       "         [-0.3809],\n",
       "         [-0.8148],\n",
       "         [ 0.1132]],\n",
       "\n",
       "        [[-0.3443],\n",
       "         [ 0.4581],\n",
       "         [ 0.1677],\n",
       "         [-0.2913],\n",
       "         [ 0.1552],\n",
       "         [-0.1299],\n",
       "         [-0.0118],\n",
       "         [ 0.0834],\n",
       "         [-0.1172],\n",
       "         [ 0.3800],\n",
       "         [ 0.1493],\n",
       "         [-0.0067],\n",
       "         [-0.1001],\n",
       "         [-0.4885],\n",
       "         [-0.4334],\n",
       "         [ 0.2364],\n",
       "         [ 0.3213],\n",
       "         [ 0.0599],\n",
       "         [ 0.0188],\n",
       "         [ 0.0395],\n",
       "         [-0.1399],\n",
       "         [-0.6422],\n",
       "         [-0.1881],\n",
       "         [-0.4766],\n",
       "         [ 0.5918],\n",
       "         [-0.1959],\n",
       "         [-0.6701],\n",
       "         [ 0.6090],\n",
       "         [-0.4894],\n",
       "         [ 0.0925],\n",
       "         [-0.1163],\n",
       "         [-0.1762],\n",
       "         [-0.1250],\n",
       "         [-0.2234],\n",
       "         [-0.6302],\n",
       "         [-0.0458],\n",
       "         [-0.0745],\n",
       "         [-0.3705],\n",
       "         [-0.3642],\n",
       "         [-0.2698],\n",
       "         [ 0.0224],\n",
       "         [ 0.0150],\n",
       "         [ 0.2430],\n",
       "         [-0.3267],\n",
       "         [ 0.1290],\n",
       "         [-0.0826],\n",
       "         [-0.6980],\n",
       "         [-0.1407]]], grad_fn=<AsStridedBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear1 = nn.Linear(240 , 48)\n",
    "output = linear1(data)\n",
    "output.reshape(10,48 ,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数标准化 uniform_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[7.8473e-44, 8.1275e-44, 6.7262e-44, 7.8473e-44],\n",
       "        [8.1275e-44, 7.2868e-44, 7.5670e-44, 6.4460e-44],\n",
       "        [6.7262e-44, 7.7071e-44, 7.8473e-44, 7.7071e-44],\n",
       "        [7.0065e-44, 7.0065e-44, 1.2612e-43, 0.0000e+00]], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.parameter import Parameter\n",
    "p1 = Parameter(torch.FloatTensor(4, 4))\n",
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4916, -0.4412, -0.0049, -0.2021],\n",
       "        [ 0.3667,  0.0841,  0.1413, -0.3793],\n",
       "        [-0.2038, -0.1635,  0.3213,  0.3987],\n",
       "        [ 0.2851, -0.3253, -0.4595, -0.2169]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.data.uniform_(-0.5 , 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2734,  0.0336,  0.0456, -0.0205],\n",
       "        [ 0.3176,  0.3502,  0.4384,  0.4363],\n",
       "        [ 0.4543,  0.0495, -0.2174, -0.2109],\n",
       "        [-0.4292, -0.4744,  0.4126, -0.0116]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "weight = Parameter(torch.FloatTensor(4, 4))\n",
    "stdv = 1. / math.sqrt(weight.size(1))\n",
    "weight.data.uniform_(-stdv, stdv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 定义参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.param = nn.Parameter(torch.rand(3,3)) \n",
    "        # 等价与self.register_parameter('param1' ,nn.Parameter(t.randn(3, 3)))\n",
    "    def forward(self,input):\n",
    "        x = self.param.mm(input)\n",
    "        return x \n",
    "n = Net()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.register_parameter('param',nn.Parameter(torch.randn(3, 3)))\n",
    "    def forward(self,input):\n",
    "        x = self.param.mm(input)\n",
    "        return x \n",
    "n = Net()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cluster gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.randint(3, 5, (10,2))  # n , k\n",
    "w = torch.randint(3, 5, (2,3,4)) #  k , f1, f2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.mm(c,w.view(2,-1)) # n , f1*f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.view(10,3,4).shape # n , f1 , f2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = nn.Parameter(torch.rand(10,2,3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "con1 = nn.Conv2d(1, 1, 16) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw( c , w):\n",
    "    \"\"\"\n",
    "    input:  \n",
    "    output : w of clustered \n",
    "    \"\"\"\n",
    "    CW = []\n",
    "    for i in range(c.shape[0]):\n",
    "        w_i = c[i][0] * w[0] + c[i][1]*w[1] + c[i][2] *w[2] \n",
    "        CW.append(w_i)\n",
    "    return CW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.rand(10 ,3 )  # v , k \n",
    "w = torch.rand(3,2,2)  # v , f1, f2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### soft cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = nn.Linear(5 , 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4,2, 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear1(x).view(4,2,3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3, 5])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 矩阵间的欧式距离\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1000,  0.1000],\n",
       "        [ 0.1000, -0.1000]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.Tensor( [[0.1 , 0.9], [0.2,0.8]] ) \n",
    "B = torch.Tensor([[0.2 , 0.8], [0.1,0.9] ])\n",
    "C = torch.Tensor([[0.1 , 0.9], [0.2,0.8] ])\n",
    "C = A - B \n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0400)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(C**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_distance(A,B):\n",
    "    D = A - B\n",
    "    return torch.sum( D**2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 排列组合\n",
    "import itertools\n",
    "list(itertools.permutations([1,2,3,4],2))\n",
    "list(itertools.combinations([1,2,3,4],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[0.1000, 0.9000],\n",
       "          [0.2000, 0.8000]]), tensor([[0.2000, 0.8000],\n",
       "          [0.1000, 0.9000]])), (tensor([[0.1000, 0.9000],\n",
       "          [0.2000, 0.8000]]), tensor([[0.1000, 0.9000],\n",
       "          [0.2000, 0.8000]])), (tensor([[0.2000, 0.8000],\n",
       "          [0.1000, 0.9000]]), tensor([[0.1000, 0.9000],\n",
       "          [0.2000, 0.8000]]))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.Tensor( [[0.1 , 0.9], [0.2,0.8]] ) \n",
    "B = torch.Tensor([[0.2 , 0.8], [0.1,0.9] ])\n",
    "C = torch.Tensor([[0.1 , 0.9], [0.2,0.8] ])\n",
    "D = torch.Tensor([[0.3 , 0.7], [0.6,0.4] ])\n",
    "list(itertools.combinations([A , B , C],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_distance(A,B):\n",
    "    D = A - B\n",
    "    return torch.sum(D**2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def cluster_distance(m_list):\n",
    "    p = list(itertools.combinations(m_list,2))\n",
    "    res = 0 \n",
    "    for item in p:\n",
    "        res_item = matrix_distance(item[0] , item[1])\n",
    "        res += res_item\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_distance([A,B,C,D])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "train_dataset = torch.rand(50, 10 , 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=10, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([10, 10, 5])\n",
      "1 torch.Size([10, 10, 5])\n",
      "2 torch.Size([10, 10, 5])\n",
      "3 torch.Size([10, 10, 5])\n",
      "4 torch.Size([10, 10, 5])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_loader): \n",
    "    print(i,data.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### cluster distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def matrix_distance(A,B):\n",
    "    D = A - B\n",
    "    return torch.mean(D**2) \n",
    "def cluster_distance(m_list):\n",
    "    p = list(itertools.combinations(m_list,2))\n",
    "    res = []\n",
    "    for item in p:\n",
    "        res_item = matrix_distance(item[0] , item[1])\n",
    "        res.append(res_item)\n",
    "        res = torch.Tensor( res ) \n",
    "    return torch.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.Tensor( [[0.1 , 0.9], [0.2,0.8]] ) \n",
    "B = torch.Tensor([[0.2 , 0.8], [0.1,0.9] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_distance([A,B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### graph to batch graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2., 3.],\n",
      "         [5., 6.]],\n",
      "\n",
      "        [[2., 3.],\n",
      "         [5., 6.]]])\n"
     ]
    }
   ],
   "source": [
    "graph = torch.Tensor( [ [2,3], [5,6] ])\n",
    "graph.unsqueeze(0)\n",
    "graph = graph.repeat(2 ,1,1) \n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 软分类 to 硬分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9000, 0.1000],\n",
       "        [0.2000, 0.8000],\n",
       "        [0.8000, 0.2000],\n",
       "        [0.7000, 0.3000]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = torch.Tensor([[0.9,0.1],[0.2,0.8] , [0.8,0.2] , [0.7,0.3] ])\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9000, 0.8000, 0.8000, 0.7000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(cluster , 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.transpose(torch.max(cluster , 1)[0].repeat(2,1),0,1)\n",
    "a = torch.ones(4,2)\n",
    "b = torch.zeros(4,2)\n",
    "torch.where(cluster-m>=0 , a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_cluster = torch.Tensor([[[0.9,0.1,0.1],[0.2,0.4,0.8] , [0.8,0.6,0.2] , [0.7,0.3,0.1]]])\n",
    "soft_cluster.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9000, 0.9000, 0.9000],\n",
       "         [0.8000, 0.8000, 0.8000],\n",
       "         [0.8000, 0.8000, 0.8000],\n",
       "         [0.7000, 0.7000, 0.7000]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_mat = torch.max(soft_cluster, -1)[0].unsqueeze(-1).repeat(1, 1, 3)\n",
    "max_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.rand([1, 4 ,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9000, 0.8000, 0.8000, 0.7000]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(soft_cluster, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(1,4,3)\n",
    "b = torch.zeros(1,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_cluster = torch.where(soft_cluster-max_mat >=0 , a , b)\n",
    "hard_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_cluster[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8020, 0.2433, 0.5654],\n",
       "         [0.7393, 0.5971, 0.2951],\n",
       "         [0.7850, 0.3613, 0.4925],\n",
       "         [0.8192, 0.9343, 0.2774]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8020, 0.2433, 0.5654],\n",
       "         [0.0000, 0.0000, 0.0000],\n",
       "         [0.7850, 0.3613, 0.4925],\n",
       "         [0.8192, 0.9343, 0.2774]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(out ,hard_cluster[:, :, 0].unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 1.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_2D = torch.FloatTensor((np.random.rand(4,4)>0.9).astype(np.int))\n",
    "graph_2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2],[3,4]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 3.],\n",
       "        [2., 4.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(x, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 3.],\n",
       "        [2., 4.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(1,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3,3, 5)\n",
    "b = torch.rand(5,1)\n",
    "torch.matmul(a,b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
