{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sentences = [\"the quick brown fox jumps over the lazy dogs\",\"yoyoyo you go home now to sleep\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dogs'],\n",
       " ['yoyoyo', 'you', 'go', 'home', 'now', 'to', 'sleep']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences= [s.split() for s in raw_sentences]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型参数设置\n",
    "- size参数主要是用来设置神经网络的层数，Word2Vec 中的默认值是设置为100层\n",
    "- 较大的语料集中，我们希望忽略那些只出现过一两次的单词，这里我们就可以通过设置min_count参数进行控制\n",
    "- workers参数用于设置并发训练时候的线程数\n",
    "- iter (int, optional) – 迭代次数，默认为5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuanbo6/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.065726176"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('dogs','you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuanbo6/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('to', 0.11079460382461548)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['fox'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuanbo6/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 8.8661059e-04, -2.8677164e-03,  1.3770671e-03, -3.4303158e-03,\n",
       "        3.4532512e-03,  9.9979131e-04,  4.2418330e-03, -3.7468646e-03,\n",
       "       -4.3298625e-03, -1.9489299e-03, -4.5547145e-05,  1.5459687e-03,\n",
       "       -4.9540563e-03,  1.0288750e-03, -3.4758374e-03,  1.6700967e-03,\n",
       "        4.2072465e-03, -4.2155758e-03,  2.5911939e-03, -3.9270613e-03,\n",
       "        4.0532369e-03,  3.9700223e-03,  3.9611394e-03, -4.3871934e-03,\n",
       "        4.4010696e-03, -2.9229163e-03, -4.7167419e-03, -4.6981752e-04,\n",
       "       -3.3993401e-05,  1.9880391e-03, -2.6971735e-03, -3.3250172e-03,\n",
       "        4.0065139e-03, -5.0257461e-04,  4.2591318e-03, -8.6755864e-04,\n",
       "        8.6930773e-04, -4.2815353e-03, -9.7108813e-04, -1.7702893e-03,\n",
       "       -4.0077642e-03, -1.3982233e-03, -3.1770754e-03, -2.0635424e-03,\n",
       "       -1.5898180e-03, -4.8664431e-03,  1.3960754e-03,  4.3822858e-03,\n",
       "       -2.7520978e-03, -3.7752101e-03, -4.5202202e-03,  1.1516053e-03,\n",
       "       -9.1030757e-04, -7.1200408e-04, -3.9792755e-03,  1.1037950e-03,\n",
       "        8.6227042e-04, -2.2842023e-04, -1.9519445e-03, -2.6104795e-03,\n",
       "        4.3246062e-03, -3.1141506e-03, -2.5602931e-03, -3.6908053e-03,\n",
       "       -2.3698558e-03,  9.7536400e-04,  1.1157388e-03,  3.8894845e-04,\n",
       "        1.6785584e-03, -3.7793890e-03, -8.9558150e-04, -2.7896743e-03,\n",
       "       -1.6883072e-03, -9.2538859e-04, -8.6077966e-04, -4.4884975e-03,\n",
       "        4.0430399e-03,  1.4904913e-03,  3.8094954e-03,  2.3550170e-03,\n",
       "        8.2177838e-04,  1.1829392e-03, -2.6507587e-03,  9.8666502e-04,\n",
       "       -2.4870317e-03, -4.9196789e-03, -4.1610640e-03, -3.7781525e-04,\n",
       "       -1.0606253e-03, -1.8007547e-03,  4.8601101e-03, -1.7721327e-03,\n",
       "        9.0949284e-04,  2.3709289e-03,  4.4514807e-03,  2.1849812e-03,\n",
       "        3.5582685e-03, -1.8195681e-04,  2.8010588e-03, -1.5454211e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 得到某个单词的embedding向量\n",
    "model['dogs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型save和load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gensim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-b7a7e982baec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 模型save和load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mymodel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mymodel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gensim' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('mymodel')\n",
    "new_model = gensim.models.Word2Vec.load('mymodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存得到的词向量\n",
    "model.wv.save_word2vec_format(outp2, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LineSentence\n",
    "文件的每行是一个句子\n",
    "\n",
    "按行读取，不占用过大内存\n",
    "\n",
    "max_sentence_length是返回的每句话中元素的最大个数，limit=3是说读取sample_text.txt中的前三行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infilename = 'sample_text.txt'\n",
    "lines = gensim.models.word2vec.LineSentence(infilename, max_sentence_length=10, limit=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用skip-gram\n",
    "\n",
    "skip-gram 对低频词汇表现更好\n",
    "\n",
    "“Skip-gram: works well with small amount of the training data, represents well even rare words or phrases\n",
    "\n",
    "CBOW: several times faster to train than the skip-gram, slightly better accuracy for the frequent words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "默认的设置是CBOW，如你设置word2vec的模型参数sg=1\n",
    "\n",
    "gensim.models.word2vec.Word2Vec(sentences, sg=1)\n",
    "那么就是用的skip-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### window\n",
    "\n",
    "window是指两端到中心词的距离，你上面的例子window=1\n",
    "\n",
    "window=2，就是x, x, center, x, x\n",
    "\n",
    "window=4，就是x, x, x, x, center, x, x, x, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 增量训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "new_model = Word2Vec.load(outp_modle)\n",
    "\n",
    "# 新的数据需要更新到词表中，在加载模型之后添加\n",
    "model.build_vocab(LineSentence(new_file),update=True)\n",
    "\n",
    "# 训练新模型\n",
    "trainedWordCount = model.train(LineSentence(inp_file), total_examples=model.corpus_count, epochs=model.iter)\n",
    "\n",
    "# 打印增量\n",
    "print('update model, update words num is: ' + str(trainedWordCount))\n",
    "\n",
    "# 存储新模型\n",
    "model.save(outp_model)\n",
    "model.wv.save_word2vec_format(outp_vector, binary=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
