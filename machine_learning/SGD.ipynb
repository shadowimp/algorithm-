{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 初始化grad\n",
    "beta = [1,1]\n",
    "alpha = 0.2 \n",
    "tol = 0.1 #阈值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\nabla L = \\left(\\frac{\\partial L}{\\partial \\beta_0^i}, \\frac{\\partial L}{\\partial \\beta_1^i}\\right)=\\left(\\frac{2}{N}\\sum_{j=1}^N(\\beta_0^i+\\beta_1^ix_j-\\hat y_j), \\frac{2}{N}\\sum_{j=1}^Nx_j(\\beta_0^i+\\beta_1^ix_j-\\hat y_j)\\right) $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_grad(beta , x , y):\n",
    "    grad = [0,0]\n",
    "    grad[0] = 2. * np.mean(beta[0] + beta[1] * x - y)\n",
    "    grad[1] = 2. * np.mean(x * ( beta[0] + beta[1] * x - y))\n",
    "    return np.array(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\beta^{i+1} = \\beta^i - \\alpha  \\nabla L_{\\beta^i}  $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_beta(beta, alpha , grad ):\n",
    "    return np.array(beta) - alpha*grad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$MAE = \\frac{1}{n} \\sum^n_i |{\\hat y_i - y_i } | $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{MAPE}=\\frac{1}{n}\\sum_{i=1}^n\\frac{|\\hat y_i - y_i|}{y_{i}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ MSE = \\frac{ 1}{ n} \\sum ^ n_{i=1}(\\hat y_i - y_i)^2  $ \n",
    "\n",
    "就是简单的线性回归的损失函数嘛"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n} (\\hat y_i - y_i)^2} $ \n",
    "\n",
    "RMSE的量纲跟数据一致，这样可以更直观,要做房价预测，每平方是万元（真贵），我们预测结果也是万元。那么差值的平方单位应该是 千万级别的。那我们不太好描述自己做的模型效果。怎么说呢？我们的模型误差是 多少千万？。。。。。。于是干脆就开个根号就好了。我们误差的结果就跟我们数据是一个级别的可，在描述模型的时候就说，我们模型的误差是多少万元。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(beta, x , y):\n",
    "    mse = np.mean( (beta[0] + beta[1]*x - y )**2 )\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         id        date  questions  answers\n",
       "0        1  2010-10-01        742     1561\n",
       "1        2  2010-10-02        400      783\n",
       "2        3  2010-10-03        388      771\n",
       "3        4  2010-10-04        762     1474\n",
       "4        5  2010-10-05        821     1639\n",
       "5        6  2010-10-06        876     1730\n",
       "6        7  2010-10-07        854     1719\n",
       "7        8  2010-10-08        793     1589\n",
       "8        9  2010-10-09        327      641\n",
       "9       10  2010-10-10        436      844\n",
       "10      11  2010-10-11        780     1544\n",
       "11      12  2010-10-12        863     1775\n",
       "12      13  2010-10-13        883     1735\n",
       "13      14  2010-10-14        911     1815\n",
       "14      15  2010-10-15        785     1677\n",
       "15      16  2010-10-16        423      889\n",
       "16      17  2010-10-17        434      909\n",
       "17      18  2010-10-18        825     1681\n",
       "18      19  2010-10-19        892     1834\n",
       "19      20  2010-10-20        913     1819\n",
       "20      21  2010-10-21        942     1890\n",
       "21      22  2010-10-22        851     1726\n",
       "22      23  2010-10-23        488      994\n",
       "23      24  2010-10-24        450      903\n",
       "24      25  2010-10-25        848     1719\n",
       "25      26  2010-10-26        897     1814\n",
       "26      27  2010-10-27        953     1915\n",
       "27      28  2010-10-28        907     1853\n",
       "28      29  2010-10-29        830     1724\n",
       "29      30  2010-10-30        468      944\n",
       "...    ...         ...        ...      ...\n",
       "2223  2224  2016-11-01       5649    10636\n",
       "2224  2225  2016-11-02       6069    11175\n",
       "2225  2226  2016-11-03       6128    11189\n",
       "2226  2227  2016-11-04       5798    11079\n",
       "2227  2228  2016-11-05       4637     9435\n",
       "2228  2229  2016-11-06       4693     9439\n",
       "2229  2230  2016-11-07       6020    11066\n",
       "2230  2231  2016-11-08       6124    11270\n",
       "2231  2232  2016-11-09       5879    10816\n",
       "2232  2233  2016-11-10       6092    11187\n",
       "2233  2234  2016-11-11       5780    10802\n",
       "2234  2235  2016-11-12       4647     9382\n",
       "2235  2236  2016-11-13       4646     9425\n",
       "2236  2237  2016-11-14       5877    10893\n",
       "2237  2238  2016-11-15       6152    11353\n",
       "2238  2239  2016-11-16       6232    11580\n",
       "2239  2240  2016-11-17       6273    11509\n",
       "2240  2241  2016-11-18       5924    11205\n",
       "2241  2242  2016-11-19       4706     9547\n",
       "2242  2243  2016-11-20       4771     9552\n",
       "2243  2244  2016-11-21       6023    11132\n",
       "2244  2245  2016-11-22       6176    11426\n",
       "2245  2246  2016-11-23       6180    11528\n",
       "2246  2247  2016-11-24       5833    11091\n",
       "2247  2248  2016-11-25       5575    10680\n",
       "2248  2249  2016-11-26       4606     9423\n",
       "2249  2250  2016-11-27       4692     9397\n",
       "2250  2251  2016-11-28       5944    11110\n",
       "2251  2252  2016-11-29       6220    11538\n",
       "2252  2253  2016-11-30       6234    11537\n",
       "\n",
       "[2253 rows x 4 columns]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y = train['id'], train['questions']\n",
    "grad = compute_grad(beta, x,y )\n",
    "loss = rmse(beta, x, y)\n",
    "beta = update_beta(beta, alpha, grad)\n",
    "loss_new = rmse(beta, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef: 1230750.59964 \n",
      "Intercept 913.668264536\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "while np.abs(loss_new - loss) > tol:\n",
    "    beta = update_beta(beta, alpha, grad)\n",
    "    grad = compute_grad(beta, x, y)\n",
    "    loss = loss_new\n",
    "    loss_new = rmse(beta, x, y)\n",
    "    i += 1\n",
    "    print('Round %s Diff RMSE %s'%(i, abs(loss_new - loss)))\n",
    "print('Coef: %s \\nIntercept %s'%(beta[1], beta[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
